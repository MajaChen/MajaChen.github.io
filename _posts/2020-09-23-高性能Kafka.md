---
layout: post
title: 高性能kafka
subtitle: kafka design page cache zero copy 
cover-img: /assets/img/path.jpg
thumbnail-img: /assets/img/thumb.png
share-img: /assets/img/path.jpg
tags: [tool,kafka]
---

# 高性能kafka

&emsp;&emsp;kafka作为一款非常成功的开源组件，它背后蕴含的设计理念值得我们去深入地探讨和学习。这篇文章尝试从最最宏观的层面分析kafka高性能背后的支撑因素，不涉及任何实现细节。
## 1.kafka有多强

&emsp;&emsp;我们来看对kafka的基准测试结果，kafka版本是0.8.1,主机硬件配置：

- intel Xeon 2.5 GHz processor with six cores

- Six 7200 RPM SATA drives

- 32GB of RAM

- 1Gb Ethernet

  &emsp;&emsp;总共有6个这样的结点，brokers部署于其中的三个节点，各有一个producer和consumer部署于剩余结点，partitions个数为6，副本个数为3，采用[ async replication]()模式，基准测试结果如下：795,064 records/sec 75.8 MB/sec。<br>
  &emsp;&emsp;更多的基准测试数据可以访问[这里](https://majachen.github.io/resources/htmls/blogs/kafka专项/Benchmarking Apache Kafka_ 2 Million Writes Per Second (On Three Cheap Machines) _ LinkedIn Engineering.html)。

## 2.page-cache centritic
&emsp;&emsp;现代计算机系统采用多级缓存的存储结构，从上到下依次是高速缓存(可能有多级)->内存->磁盘，不同层次间的存储设备在访问速度上存在很大差异，内存与磁盘之间的速度差距更是达到数十万倍。kafka作为一个分布式消息队列，其基本操作是把producer产生的数据写入磁盘，再把磁盘上的数据通过socket发送给consumer，整个过程涉及到大量的磁盘io操作。

![image-20210706164204053](https://gitee.com/xinyuanchen/image_collection/raw/master/image-20210706164204053.png)

&emsp;&emsp;如果这些操作能够基于缓存，即producer数据先写入到缓存，再直接从缓存把数据发送到consumer(当然，数据写入到缓存之后，借助于Linux的[flush线程]()把数据异步地刷写回磁盘，但是这些刷写操作于读写操作而言是透明的)

![image-20210706164238868](https://gitee.com/xinyuanchen/image_collection/raw/master/image-20210706164238868.png)

&emsp;&emsp;那我们看看，kafka是如何把看似不可能变成可能的呢？

### 2.1 page cache
&emsp;&emsp;现代操作系统每个进程都有自己的虚拟地址空间，对应多个页的集合，由于内存空间有限，某一时刻，只有进程正在使用的页才会被加载到内存，这样进程就不用访问磁盘，可以大大提高进程的运行速度。

![image-20210706164852412](https://gitee.com/xinyuanchen/image_collection/raw/master/image-20210706164852412.png)

&emsp;&emsp;如图，进程的page_1/2/3/5逻辑页被加载到内存，但是由于内存的容量有限或者page_4当前没有被用到等原因，page_4没有被加载到内存。如果进程在运行的过程中，需要访问到落在page_4地址空间内的地址，那么page_4也会被加载到内存，但是如果系统没有可用的物理内存页，那么根据选择替换算法，其中的一个逻辑页必须被替换出去，我们假设page3被选中并被替换出去,page_x+1空出，然后page_4被加载到page_x+1

![image-20210706194058953](https://gitee.com/xinyuanchen/image_collection/raw/master/image-20210706194058953.png)

page cache就是指这一整套内存管理机制。欲了解更多关于page cache的内容，可参考[《深入理解计算机系统》](https://github.com/MajaChen/resources)chapter 9关于虚拟内存的相关知识。这里需要澄清一点：<br>

- 虚拟地址空间：以进程为单位，每个进程有独立的虚拟地址空间，每个进程的虚拟地址空间都是从0开始；
- 物理地址空间：与进程无关，所有地址都是唯一的；

### 2.2 In-memory cache
&emsp;&emsp;它指的是由应用自己建立一套内存管理机制，管理应用在运行过程中的内存申请和释放。一个典型的例子是jvm：在main函数启动地时候，它首先从操作系统申请一块定长内存(假设-Xms=-Xmx)，然后将其作为一个缓存池，线程需要内存就从缓冲池中申请内存，用完的内存通过GC归还给缓冲池。(这个说法不够严谨，因为jvm管理的内存池的大小是可变的，而且每次FullGC会触发jvm缓慢地向操作系统归还内存，但是这里暂且我们忽略这些细节。如果对jvm与操作系统的内存交部分互感兴趣，可以参考相关文章。)

![image-20210706170811116](https://gitee.com/xinyuanchen/image_collection/raw/master/image-20210706170811116.png)

### 2.3 顺序读写/read-before/write-behind

 &emsp;&emsp;kafka的读取和写入都是对topic下的partition进行的，归根结底是对partition的日志文件进行的，例如写入操作就是把消息append到日志文件。这个读取和写入操作都是顺序的，避免了磁盘的寻址操作,时间复杂度为O(1)。<br>
&emsp;&emsp;现代操作系统提供了提前读和延迟写的功能。预先读——读取某个块的时候，预先读取这个块之后的多个块到缓存中，在顺序读取的情况下，后续的读取操作就可以直接基于缓存；延迟写——每次对缓存块的写入，并不会触发缓存块与磁盘块之间的立即同步，而是等到这个块被替换出去的时候才写入，在顺序写入的情况下，多个连续的写入都是基于同一个块，能最大程度地发挥延迟写的优势，减少刷盘操作。

### 2.4 步入正题

 kafka基于scala和java，所以它运行于jvm之上，但是直接基于page-cache进行数据管理。

![image-20210706171322768](https://gitee.com/xinyuanchen/image_collection/raw/master/image-20210706171322768.png)

&emsp;&emsp;kafka在启动的时候，会发射访问虚拟地址空间的指令，将尽可能多的逻辑页加载到缓存中，尽可能地填充page cache。后续的顺序读取和写入操作能够获得极高的缓存命中率，从而基本避免了访盘。反之，如果把数据管理的重任交给jvm，它将由于频繁gc不堪重负，而且每次应用重启，in-process 内的数据将会丢失，而page cache则不会。<br>
&emsp;&emsp;而且，这种机制与zero copy结合起来之后，作用将发挥的更加地明显。

## 3.zero-copy

 &emsp;&emsp;我们来看看把数据从磁盘读出然后通过socket发送出去，这中间经历的拷贝操作有哪些：

![image-20210706171427951](https://gitee.com/xinyuanchen/image_collection/raw/master/image-20210706171427951.png)

&emsp;&emsp;可以看到有两次系统调用(一次是读盘，一次是网络socket)，经历了四次copy，但是其中最关键的第二步：即把数据从page cache读取到应用缓冲区，进行处理，再从应用缓冲区把数据发送到网络，没有任何实质性意义，因为对于kafka来说，它只是简单地转发数据，而不对数据进行任何处理，所以第二、三步完全多余。可以通过unix系统提供的系统调用sendfile，将数据从page cache直接传送到NIC buffer

![image-20210706171716471](https://gitee.com/xinyuanchen/image_collection/raw/master/image-20210706171716471.png)

&emsp;&emsp;再结合page-cache centritic的设计，producer生产的数据到达broker之后，写入操作大概率命中pagecache,然后通过零拷贝技术，数据直接从page cache传送到NIC buffer,通过socket发送给consumer，无访盘操作。

&emsp;&emsp;所以在“大多数 consumer 消费时”的情况下，对文件的读写操作基本上可以基于缓存，或者说，是基于内存。我们知道，redis是一个基于内存的k-v存储系统，由于其速度快，所以被广泛地应用在缓存系统的构建中。而kafka在特定情况下，也可以做到基于内存。<br>
&emsp;&emsp;那么，kafka的基于缓存的优势，在什么条件下会被打破呢

## 4.基于缓存的读写被打破

&emsp;&emsp;为了简化讨论，我们只考虑两个consumer(准确来讲，是两个consumer group)对一个partition消费的情况，在理想情况下，两个consumer的步调是一致的，即同时访问日志文件的相邻部分，具有很好的局部性，那么这部分对应的page在缓存中就可以发挥最大的效益。

![image-20210706172618043](https://gitee.com/xinyuanchen/image_collection/raw/master/image-20210706172618043.png)

&emsp;&emsp;反之，如果两个consumer的步调不一致，consumerA与consumerB分别访问日志文件不相邻的部分，各自对应的page需要被单独缓存，原来只需要一个缓存页，现在需要两个

![image-20210706172729227](https://gitee.com/xinyuanchen/image_collection/raw/master/image-20210706172729227.png)

&emsp;&emsp;把这种情况扩充一下，在多个consumer访问多个partitions而且consumers之间的访问不具有局部性的时候，就需要大量的缓存页，降低了内存的使用效率，在缓存空间有限的情况下，可能会有大量的页频繁地被换入换出，此时，基于缓存的读写自然无法保证，kafka的性能会严重下降。

## 总结

&emsp;&emsp;其实kafka还有很多优秀的设计，比如批处理、压缩等，但是这些点比较零散，而且这些设计理念相对来说比较常见，本文章就不一一列举。如果想获得对于kafka设计百科全书式地了解，还是建议参看[官方文档](https://kafka.apachecn.org/)。