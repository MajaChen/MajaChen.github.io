---
layout: post
title: 走近Kafka
subtitle: kafka archtecture
cover-img: /assets/img/path.jpg
thumbnail-img: /assets/img/animals/Heliodoxa.jpg
share-img: /assets/img/path.jpg
tags: [tool,kafka]
---

# 走近Kafka

&emsp;&emsp;公司项目用kafka构建实时流数据管道，用于在不同的模块之间交换数据，毕业论文也有与kafka相关的内容，故趁此机会，了解一下kafka。

## kafka是什么？有什么用？

&emsp;&emsp;kafka是一个分布式消息队列，用于在不同的实体之间交换数据，可以把它想象成一个管道，管道的一端是生产者，生产数据,另一端是消费者，消费数据：

![image-20210702215224167](https://gitee.com/xinyuanchen/image_collection/raw/master/image-20210702215224167.png)

&emsp;&emsp;另外，在数据流经管道的时候，也可以利用kafka提供的api对数据进行处理，输出处理后的数据，从而构建流式应用程序：

![image-20210702215258166](https://gitee.com/xinyuanchen/image_collection/raw/master/image-20210702215258166.png)

&emsp;&emsp;那么kafka就这么点本事吗？为什么说他是分布式的？且看下文。

## 基础架构

### 静态描述

kafka的几个功能实体如下：

- producer：生产者，发布消息；

- broker:消息的中转站，她也兼具存储功能；

- consumer：消费者，订阅消息；


&emsp;&emsp;kafka的消息由三部分构成：key,value,timestamp。kafk是以topic为单位管理数据的，一个topic代表一个data uint,一个topic下面有多个partition：

![image-20210702215625877](https://gitee.com/xinyuanchen/image_collection/raw/master/image-20210702215625877.png)

&emsp;&emsp;topic和partition都是用于数据管理的逻辑实体，真正实现数据存储的是位于磁盘上的结构化的commit log，我简单把它称作日志文件，一个partition对应一个日志文件。为了容错的需要，每个partition有多个副本，副本分布在不同的结点，这些副本之间有主从关系，一个leader，多个follower，读写操作都对leader副本进行，follower副本只需要保证自己的日志文件与leader的日志文件一致，当leader结点挂掉，通过选举机制从followers中产生新的leader继续提供服务，保证服务的高可用，且保证数据不丢失：

![image-20210702215755223](https://gitee.com/xinyuanchen/image_collection/raw/master/image-20210702215755223.png)

&emsp;&emsp;每个partition中的消息都有一个ID用以唯一地标识这条消息，ID其实就是该消息在日志文件中的偏移量。这是对kafka架构的静态描述，下面引入producer和consumer进行动态描述。
### 动态描述
&emsp;&emsp;producer向选择的topic写入数据，并可以通过一些策略决定写入topic内的哪个partition，这里的策略包括循环写入各个partition,或者对key取hash code映射到不同的partition，而写入实际上就是对日志文件进行追加操作，随着追加操作的不断进行，消息的在日志文件中的偏移量会线性增大：

![image-20210702215957258](https://gitee.com/xinyuanchen/image_collection/raw/master/image-20210702215957258.png)

&emsp;&emsp;consumer以consumer group为单位从从已订阅的topic中消费数据，一个consumer group代表一个逻辑订阅者，一个consumer group包含多个consumer实例，consumer实例可以分布在不同的结点。同一个group之中的实例之间是竞争关系，即每个partition只能被其中一个实例独占式地消费，如图所示：

![image-20210702220109348](https://gitee.com/xinyuanchen/image_collection/raw/master/image-20210702220109348.png)

&emsp;&emsp;当有新的consumer 实例加入或者已有的consumer实例退出group的时候，partitions会在consumers之间转让。consumer实例是根据offset来从partition中消费数据的，每读取一条消息，offset就增大，如果没有新的数据要消费，consumer实例会一直等待新的数据到达：

![image-20210702220204246](https://gitee.com/xinyuanchen/image_collection/raw/master/image-20210702220204246.png)

&emsp;&emsp;顺序问题：同一个partition内的消息是有序的，同一个topic下不同partitions之间的消息是无序的，这里的有序指的是：消息会按照它们的发送顺序存储到partition，例如同一个producer向某partition先后发送了M1,M2两条消息，无论它们到达的先后顺序是怎样的，M1在日志文件中排在M2的前面。<br>
&emsp;&emsp;再来回答之前的问题：kakfa的分布性如何体现？

- 每个data uint(topic)有多个partition,partitions可以分布在不同的结点；

- 各个brokers部署于集群；

- 同一个consumer group的consumers实例分布于不同的结点。

- 那么，kafka有多大能耐？见后续文章!





